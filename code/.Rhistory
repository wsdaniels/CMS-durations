# accompanying manuscript.
if (z == 1){
sensors.to.use <- c("NW")
} else if (z == 2){
sensors.to.use <- c("NW", "SE")
} else if (z == 3){
sensors.to.use <- c("N", "SE",  "W" )
} else if (z == 4){
sensors.to.use <- c("E",  "N",  "SE", "W" )
} else if (z == 5){
sensors.to.use <- c("E",  "N",  "NW", "SE", "W" )
} else if (z == 6){
sensors.to.use <- c("E",  "N",  "NW", "SE", "SW", "W" )
} else if (z == 7){
sensors.to.use <- c("E",  "N",  "NE", "NW", "SE", "SW", "W" )
} else if (z == 8){
sensors.to.use <- c("E",  "N",  "NE", "NW", "S",  "SE", "SW", "W" )
}
# Pull out sensor observations and replace NA's that are not on edge of
# the time series with interpolated values
obs <- na.approx(data$obs, na.rm = F)
# Mask that grabs the z sensors to be used in the analysis
sensor.mask <- colnames(obs) %in% sensors.to.use
# Apply sensor mask to the CMS observations
obs <- as.matrix(obs[, sensor.mask])
# Number of sensors
n.r <- ncol(obs)
# Pull out time stamps of observations and simulations
times <- data$times
# Pull out the simulation predictions
sims <- data[5:length(data)]
# Apply sensor mask to the simulated concentrations
sims <- lapply(sims, function(X) as.matrix(X[, sensor.mask]))
# Grab source info
n.s <- length(sims)
source.names <- names(sims)
source.names.to.plot <- c("Tank", "East Separator", "East Wellhead", "West Wellhead", "West Separator")
# Define function to create a logarithmic spaced sequence (used later)
lseq <- function(from, to, length.out) {
exp(seq(log(from), log(to), length.out = length.out))
}
# STEP 2: REMOVE BACKGROUND FROM CMS OBSERVATIONS
#---------------------------------------------------------------------------
# Remove background from CMS observations
obs <- remove.background(obs,
going.up.threshold = 0.25, amp.threshold = 0.75,
gap.time = 30)
# STEP 3: IDENTIFY NAIVE EVENTS
#---------------------------------------------------------------------------
# Create minute-by-minute maximum value time series across all CMS sensors
max.obs <- apply(obs, 1, max, na.rm = T)
# Identify spikes in the max.obs time series. These are the "naive events"
spikes <- perform.event.detection(max.obs, gap.time = 30, length.threshold = 15)
# Pull event "event numbers" that uniquely identify each naive event
event.nums <- na.omit(unique(spikes$events))
# Number of naive events
n.ints <- length(event.nums)
# STEP 4: CREATE LOCALIZATION AND QUANTIFICATION ESTIMATES FOR EACH NAIVE EVENT
#---------------------------------------------------------------------------
# Estimate source location for each naive event
loc.est.all.events <- perform.localization(spikes, obs, sims)
# Estimate emission rate for each naive event
all.q.vals <- perform.quantification(spikes, obs, sims, loc.est.all.events, print.report = T)
# Grab emission rate point estimate and 90% interval for each naive event from the MC output
rate.est.all.events <- sapply(all.q.vals, mean, na.rm = T)
error.lower.all.events <- sapply(all.q.vals, function(X) quantile(X, probs = 0.05, na.rm = T))
error.upper.all.events <- sapply(all.q.vals, function(X) quantile(X, probs = 0.95, na.rm = T))
# STEP 5: CREATE INFORMATION MASK
#---------------------------------------------------------------------------
# Scale simulations by the estimated emission rate for each naive event
sims <- scale.sims(sims)
# Create information mask based on simulated concentrations
info.list <- create.info.mask(sims)
# STEP 6: ELIMINATE MULTISOURCE LEAKS
#---------------------------------------------------------------------------
# NOTE: This step is the only difference from the main duration estimation code.
# This is done because we evaluate on single-source leaks only, as the model still
# assumes that only one thing is emitting at a time.
# Read in leak data
leak.data <- suppressWarnings(read.csv('/Users/wdaniels/Documents/papers/duration_model/leak_data.csv'))
# Determine unique equipment group IDs
unique.eg <- unique(leak.data$tc_EquipmentGroupID)
# Names to replace equipment group IDs. Order is set manually.
eg.names <- c("Tank", "Wellhead.East", "Wellhead.West", "Separator.East", "Separator.West")
# Replace equipment group ID values with names
for (i in 1:length(unique.eg)){
this.mask <- leak.data$tc_EquipmentGroupID == unique.eg[i]
leak.data$tc_EquipmentGroupID[this.mask] <- eg.names[i]
}
# Convert time strings to datetime objects
leak.data$tc_ExpStartDatetime <- as_datetime(as_datetime(leak.data$tc_ExpStartDatetime), tz = "America/Denver")
leak.data$tc_ExpEndDatetime <- as_datetime(as_datetime(leak.data$tc_ExpEndDatetime), tz = "America/Denver")
# Mask in leak data during simulation time frame
to.keep <- leak.data$tc_ExpStartDatetime >= times[1] & leak.data$tc_ExpStartDatetime <= times[length(times)]
leak.data <- leak.data[to.keep,]
# Sort by leak start time
leak.data <- leak.data[order(leak.data$tc_ExpStartDatetime), ]
# Figure out when multisource leaks are happening
multisource <- rep(F, nrow(leak.data))
for (i in 1:(nrow(leak.data)-1)){
for (j in (i+1):nrow(leak.data)){
first.leak.start <- leak.data$tc_ExpStartDatetime[i]
first.leak.stop  <- leak.data$tc_ExpEndDatetime[i]
first.leak.times <- seq(first.leak.start, first.leak.stop, by = "1 min")
first.leak.times <- round_date(first.leak.times, unit = "min")
second.leak.start <- leak.data$tc_ExpStartDatetime[j]
second.leak.stop  <- leak.data$tc_ExpEndDatetime[j]
second.leak.times <- seq(second.leak.start, second.leak.stop, by = "1 min")
second.leak.times <- round_date(second.leak.times, unit = "min")
if (any(first.leak.times %in% second.leak.times)){
multisource[c(i,j)] <- T
}
}
}
# Separate out the single and multisource leaks
singlesource.leaks <- leak.data[!multisource, ]
multisource.leaks <- leak.data[multisource, ]
# Number of METEC emission events
n.leaks <- nrow(singlesource.leaks)
# Initialize vector to hold estimated events that should be removed because
# they overlap with a multisource leak
to.remove <- vector(length = length(event.nums))
# Remove events that overlap with a multisource leak
for (i in 1:length(event.nums)){
# Mask in this event
this.spike <- which(spikes$events == event.nums[i])
these.times <- spikes$time[this.spike]
# Loop through multisource leaks
for (j in 1:nrow(multisource.leaks)){
leak.start <- multisource.leaks$tc_ExpStartDatetime[j]
leak.stop  <- multisource.leaks$tc_ExpEndDatetime[j]
# If there is any overlap between estimated event and leak, remove
# the event
if (any(these.times >= leak.start & these.times <= leak.stop)){
spikes$events[this.spike] <- NA
to.remove[i] <- T
break
}
}
}
# Get event numbers after filtering out events that overlap with multisource leaks
event.nums <- na.omit(unique(spikes$events))
# Number of events after filtering multisource leaks
n.ints <- length(event.nums)
# Filter out all naive events that occurred during a multi-source release
rate.est.all.events <- rate.est.all.events[!to.remove]
error.lower.all.events <- error.lower.all.events[!to.remove]
error.upper.all.events <- error.upper.all.events[!to.remove]
loc.est.all.events <- loc.est.all.events[!to.remove]
all.q.vals <- all.q.vals[!to.remove]
# STEP 7: PREP DETECTION RESULTS
#---------------------------------------------------------------------------
# Initialize matrix to hold information on which controlled release
# each naive event overlaps with.
# Rows are the METEC controlled releases, columns are naive events.
# True indicates an estimated event overlaps with a controlled release.
overlap.matrix <- matrix(NA, nrow = n.leaks, ncol = n.ints)
overlap.matrix[is.na(overlap.matrix)] <- F
# Fill in the overlap matrix. First loop over METEC emissions.
for (l in 1:n.leaks){
# Grab start and stop times of the METEC emission
leak.start <- singlesource.leaks$tc_ExpStartDatetime[l]
leak.end   <- singlesource.leaks$tc_ExpEndDatetime[l]
# Create minute sequence over duration of METEC emission
leak.times <- seq(leak.start, leak.end, by = "1 min")
leak.times <- round_date(leak.times, unit = "min")
# Loop over predicted events.
for (t in 1:n.ints){
# Create minute sequence over duration of this predicted event.
this.mask <- seq(min(which(spikes$events == event.nums[t])),
max(which(spikes$events == event.nums[t])))
event.times <- spikes$time[this.mask]
# Store overlap status
if (any(leak.times %in% event.times)){
overlap.matrix[l,t] <- T
}
}
}
# STEP 8: CHECK IF WE SHOULD COMBINE START AND END
#---------------------------------------------------------------------------
# Estimate durations. "out" contains a number of different fields (see below).
out <- get.durations(spikes = spikes, info.list = info.list, tz = "America/Denver")
# Grab distribution of possible durations for each naive event
all.durations <- out$all.durations
# Grab equipment-level duration distributions
est.durations <- out$est.durations
# Grab start time of naive events
event.starts <- out$event.starts
# Grab end time of naive events
event.ends <- out$event.ends
# Grab earliest possible start time for each naive event. The "start bounds"
start.bounds <- out$start.bounds
# Grab latest possible end time for each naive event. The "end bounds"
end.bounds <- out$end.bounds
# Calculate naive event durations
original.durations <- as.numeric(difftime(event.ends, event.starts, units = "hours"))
# Initialize variables to hold duration estimates by equipment group
# Mean of distribution of possible durations is used here
est.durations <- vector(mode = "list", length = n.s)
names(est.durations) <- source.names
# Grab durations
for (i in 1:length(all.durations)){
list.ind <- which(names(all.durations)[i] == source.names)
est.durations[[list.ind]] <- c(est.durations[[list.ind]], mean(all.durations[[i]]))
}
# Get mean and 90% interval for each equipment group across all emission events
est.average.durations <- sapply(est.durations, mean)
est.min.interval <- sapply(est.durations, function(X) quantile(X, probs = 0.05))
est.max.interval <- sapply(est.durations, function(X) quantile(X, probs = 0.95))
true.durations.matching <- true.rates.matching <- true.locs.matching <-
false.positive <- vector(length = n.ints)
for (t in 1:n.ints){
print(t)
png(paste0('/Users/wdaniels/Desktop/events/', t, ".png"),
width = 1920, height = 1080, res =100, pointsize = 24)
par(mfrow = c(2,1))
par(mar = c(2,2,2,2))
this.mask <- seq(min(which(spikes$events == event.nums[t])),
max(which(spikes$events == event.nums[t])))
info.mask <- info.list[[which(names(info.list) == loc.est.all.events[t])]]
start.time <- spikes$time[this.mask][1]- hours(12)
end.time <- spikes$time[this.mask][length(this.mask)]+ hours(12)
to.plot <- c("Wellhead.West", "Wellhead.East", "Separator.West", "Separator.East", "Tank")
if (loc.est.all.events[t] %in% to.plot){
ylim.vals <- c(event.nums[t] - 1, event.nums[t] + 1)
plot(data$times, spikes$events, pch = 19, xlim = c(start.time, end.time), ylim = ylim.vals,
col = NA, main = "")
mtext(loc.est.all.events[t], adj = 0)
abline(v = data$times[!is.na(info.mask$events)], col = alpha("royalblue", 0.25))
segments(x0 = spikes$time[this.mask], y0 = event.nums[t] - 0.25, y1 = event.nums[t] + 0.25)
for (tt in seq(1,n.ints)[-t]){
other.event.mask <- seq(min(which(spikes$events == event.nums[tt])),
max(which(spikes$events == event.nums[tt])))
segments(x0 = spikes$time[other.event.mask], y0 = event.nums[t] - 0.25, y1 = event.nums[t] + 0.25,
col = "gray44")
}
segments(x0 = start.bounds[t], y0 = event.nums[t] - 0.5, y1 = event.nums[t] + 0.5, col = "red", lwd = 2)
segments(x0 = end.bounds[t], y0 = event.nums[t] - 0.5, y1 = event.nums[t] + 0.5, col = "red", lwd= 2)
segments(x0 = spikes$time[this.mask], y0 = event.nums[t] - 0.25, y1 = event.nums[t] + 0.25)
}
if (length(which(overlap.matrix[,t])) == 0){
false.positive[t] <- T
true.durations.matching[t] <- true.rates.matching[t] <- true.locs.matching[t] <- NA
if (loc.est.all.events[t] %in% to.plot){
plot(1,1, main = t)
}
} else if (length(which(overlap.matrix[,t])) == 1){
leak.ind <- which(overlap.matrix[,t])[1]
this.true.duration <- as.numeric(difftime(singlesource.leaks$tc_ExpEndDatetime[leak.ind],
singlesource.leaks$tc_ExpStartDatetime[leak.ind],
units = "hour"))
true.rates.matching[t] <- singlesource.leaks$tc_C1MassFlow[leak.ind]
true.locs.matching[t] <- singlesource.leaks$tc_EquipmentGroupID[leak.ind]
true.durations.matching[t] <- this.true.duration
if (loc.est.all.events[t] %in% to.plot){
mtext(singlesource.leaks$tc_EquipmentGroupID[leak.ind], adj = 1)
segments(x0 = singlesource.leaks$tc_ExpStartDatetime[leak.ind],
x1 = singlesource.leaks$tc_ExpEndDatetime[leak.ind],
y0 = event.nums[t] + 0.5,
col = "forestgreen", lwd = 2)
xlim.vals <- c(0, ceiling(max(c(this.true.duration, all.durations[[t]]))))
hist(all.durations[[t]], xlim = xlim.vals, main = t, breaks = seq(0,max(xlim.vals)))
abline(v = this.true.duration, col = "orange", lwd = 8)
abline(v = mean(all.durations[[t]]), col = "blue", lwd = 6)
abline(v = original.durations[t], col = "purple", lwd = 4)
}
} else {
if (loc.est.all.events[t] %in% to.plot){
plot(1,1, main = t, pch = 19)
}
true.durations.matching[t] <- true.rates.matching[t] <- true.locs.matching[t] <- NA
print("MORE THAN 1 MATCH")
}
dev.off()
}
true.rates <- true.durations <- vector(mode = "list", length = n.s)
names(true.durations) <- source.names
names(true.rates) <- source.names
# Grab durations
for (i in 1:nrow(singlesource.leaks)){
list.ind <- which(source.names == singlesource.leaks$tc_EquipmentGroupID[i])
true.durations[[list.ind]] <- c(true.durations[[list.ind]], singlesource.leaks$tc_ExpDurationHrs[i])
true.rates[[list.ind]] <- c(true.rates[[list.ind]], singlesource.leaks$tc_C1MassFlow[i])
}
# Compute averages and 90% intervals of controlled release durations
true.average.durations <- sapply(true.durations, mean)
true.min.interval <- sapply(true.durations, function(X) quantile(X, probs = 0.05))
true.max.interval <- sapply(true.durations, function(X) quantile(X, probs = 0.95))
par(mfrow = c(3,1))
par(mar = c(2,2,2,2))
for (i in 1:n.s){
breaks.max <- ceiling(max(true.durations[[i]], est.durations[[i]], original.durations))
xlim.max <- 12
hist(true.durations[[i]], xlim = c(0,xlim.max), breaks = seq(0,breaks.max,0.5),
main = source.names[i], freq = F)
abline(v = mean(true.durations[[i]]), col = "orange", lwd = 3)
hist(est.durations[[i]], xlim = c(0,xlim.max), breaks = seq(0,breaks.max,0.5),
main = "", freq= F)
abline(v = mean(est.durations[[i]]), col = "royalblue", lwd= 3)
source.mask <- loc.est.all.events == source.names[i]
hist(original.durations[source.mask], xlim = c(0,xlim.max),
breaks = seq(0,breaks.max,0.5), main = "", freq = F)
abline(v = mean(original.durations[source.mask]), col = "purple", lwd= 3)
}
par(mfrow = c(1,1))
par(mar = c(4,8,2,2))
plot(true.average.durations, 1:5, xlim = c(0,12), pch = 19, col = "orange", ylim = c(0.5, 5.5),
yaxt = "n",
xlab = "Duration [hours]", ylab = "")
axis(side = 2, at = 1:5, labels = source.names.to.plot, las = 2)
segments(x0 = sapply(est.durations, function(X) quantile(X, probs = 0.05)),
x1 = sapply(est.durations, function(X) quantile(X, probs = 0.95)),
y0 = (1:5)+0.2, col = "blue")
points(sapply(est.durations, mean), (1:5)+0.2, col = "blue", pch = 15)
segments(x0 = sapply(true.durations, function(X) quantile(X, probs = 0.05)),
x1 = sapply(true.durations, function(X) quantile(X, probs = 0.95)),
y0 = (1:5), col = "orange")
for (i in rev(1:n.s)){
source.mask <- loc.est.all.events == source.names[i]
segments(x0 = quantile(original.durations[source.mask], probs = 0.05),
x1 = quantile(original.durations[source.mask], probs = 0.95),
y0 = 6-i-0.2, col = "purple")
print(quantile(original.durations[source.mask], probs = 0.95))
points(mean(original.durations[source.mask]), (6-i)-0.2, pch = 17, col = "purple")
}
# Set colors for plots
tank.color <- "#3062CF" #blue
tank.color <- "#3062CF" #blue
wellhead.east.color <- "#9147B8" #purple
separator.east.color <- "#7EAD52" #green
separator.west.color <- "#F1C30E" #gold
wellhead.west.color <- "#C7383C" #red
tank.pch <- 21 # circle
wellhead.east.pch <- 22 # square
separator.east.pch <- 23 # diamond
separator.west.pch <- 24 # up triangle
wellhead.west.pch <- 25 # down triangle
duration.mean <- sapply(all.durations, mean)
duration.bound.lower <- sapply(all.durations, function(X) quantile(X, probs = 0.05))
duration.bound.upper <- sapply(all.durations, function(X) quantile(X, probs = 0.95))
errors.mean <- duration.mean - true.durations.matching
errors.lower <- duration.bound.lower - true.durations.matching
errors.upper <- duration.bound.upper - true.durations.matching
plot.cols <- vector(length = n.ints)
plot.cols[true.locs.matching == "Tank"] <- tank.color
plot.cols[true.locs.matching == "Wellhead.West"] <- wellhead.west.color
plot.cols[true.locs.matching == "Separator.West"] <- separator.west.color
plot.cols[true.locs.matching == "Wellhead.East"] <- wellhead.east.color
plot.cols[true.locs.matching == "Separator.East"] <- separator.east.color
plot.cols[plot.cols == "FALSE"] <- NA
plot.pch <- vector(length = n.ints)
plot.pch[true.locs.matching == "Tank"] <- tank.pch
plot.pch[true.locs.matching == "Wellhead.West"] <- wellhead.west.pch
plot.pch[true.locs.matching == "Separator.West"] <- separator.west.pch
plot.pch[true.locs.matching == "Wellhead.East"] <- wellhead.east.pch
plot.pch[true.locs.matching == "Separator.East"] <- separator.east.pch
plot.pch[plot.pch == "FALSE"] <- NA
ylim.vals <- c(-8, 5)
par(mfrow = c(1,3))
par(mar = c(4,2,2,1))
par(oma = c(0,2,0,0))
par(mgp = c(2.5, 1, 0))
plot(true.durations.matching, errors.mean,
col = plot.cols, bg = plot.cols, pch = plot.pch, cex = 1.25,
xlim = c(0,9), ylim = ylim.vals, yaxt = "n",
xlab = "True emission duration [hours]",
ylab = "Error in duration estimate (estimate - truth) [hours]", xpd = NA)
abline(h = 0, lwd = 2)
axis(side = 2, at = seq(ylim.vals[1], ylim.vals[2], 2))
segments(x0 = true.durations.matching, y0 = errors.lower, y1 = errors.upper,
col = alpha(plot.cols, 0.5))
points(true.durations.matching, errors,
col = plot.cols, bg = plot.cols, pch = plot.pch, cex = 1.25)
legend("bottomleft",
legend = c("Tank", "West Wellhead", "West Separator", "East Wellhead", "East Separator"),
col = c(tank.color, wellhead.west.color, separator.west.color, wellhead.east.color, separator.east.color),
pt.bg = c(tank.color, wellhead.west.color, separator.west.color, wellhead.east.color, separator.east.color),
pch = c(tank.pch, wellhead.west.pch, separator.west.pch, wellhead.east.pch, separator.east.pch),
pt.cex = 1.25,
# cex = 1.15,
box.col = "white",
inset = c(0.1, 0.05))
scaled <- true.rates.matching / 1000
p.errors <- 100 * errors.mean / true.durations.matching
hist(p.errors, breaks = 20)
round(mean(p.errors, na.rm = T), 1)
round(quantile(p.errors, probs = c(0.05, 0.95), na.rm = T), 1)
round(100*sum(p.errors >= -0.5 & p.errors < 1, na.rm = T) / sum(!is.na(p.errors)), 1)
library(fields)
par(mfrow = c(1,2))
par(mgp = c(2, 0.75, 0))
par(mar = c(3.25, 1.75, 1, 1))
par(oma = c(0, 1.5, 0, 0))
tank.color <- "#3062CF" #blue
wellhead.east.color <- "#9147B8" #purple
separator.east.color <- "#7EAD52" #green
separator.west.color <- "#F1C30E" #gold
wellhead.west.color <- "#C7383C" #red
tank.color <- "#3062CF" #blue
wellhead.east.color <- "#9147B8" #purple
separator.east.color <- "#7EAD52" #green
separator.west.color <- "#F1C30E" #gold
wellhead.west.color <- "#C7383C" #red
tank.pch <- 21 # circle
wellhead.east.pch <- 22 # square
separator.east.pch <- 23 # diamond
separator.west.pch <- 24 # up triangle
wellhead.west.pch <- 25 # down triangle
duration.mean <- sapply(all.durations, mean)
duration.bound.lower <- sapply(all.durations, function(X) quantile(X, probs = 0.05))
duration.bound.upper <- sapply(all.durations, function(X) quantile(X, probs = 0.95))
p.errors <- (duration.mean - true.durations.matching) / true.durations.matching
small.mask <- true.rates.matching < 1000
big.mask <- true.rates.matching > 1000
plot.cols <- vector(length = n.ints)
plot.cols[true.locs.matching == "Tank"] <- tank.color
plot.cols[true.locs.matching == "Wellhead.West"] <- wellhead.west.color
plot.cols[true.locs.matching == "Separator.West"] <- separator.west.color
plot.cols[true.locs.matching == "Wellhead.East"] <- wellhead.east.color
plot.cols[true.locs.matching == "Separator.East"] <- separator.east.color
plot.cols[plot.cols == "FALSE"] <- NA
plot.pch <- vector(length = n.ints)
plot.pch[true.locs.matching == "Tank"] <- tank.pch
plot.pch[true.locs.matching == "Wellhead.West"] <- wellhead.west.pch
plot.pch[true.locs.matching == "Separator.West"] <- separator.west.pch
plot.pch[true.locs.matching == "Wellhead.East"] <- wellhead.east.pch
plot.pch[true.locs.matching == "Separator.East"] <- separator.east.pch
plot.pch[plot.pch == "FALSE"] <- NA
axis.vals <- c(0,12)
plot(true.durations.matching[small.mask], duration.mean[small.mask],
pch = plot.pch[small.mask],
asp = 1, col = "white",
xlim = axis.vals, ylim = axis.vals,
xlab = "True duration [hrs]",
ylab = "Estimated duration [hrs]", xpd = NA)
envelopePlot(x1 = seq(0, 20, by= 1), y1 = seq(0, 10, by = 0.5), y2 = seq(0,40, by = 2),
col = "gray90", lineCol = NA)
segments(x0 = 0, y0 = 0, x1 = 40, y1 = 40, lwd = 3, lty = 1) # 1:1
segments(x0 = true.durations.matching[small.mask],
y0 = duration.bound.lower[small.mask], y1 = duration.bound.upper[small.mask],
col = alpha(plot.cols[small.mask], 0.5))
points(true.durations.matching[small.mask], duration.mean[small.mask],
col = plot.cols[small.mask], bg = plot.cols[small.mask], pch = plot.pch[small.mask])
points(true.durations.matching[small.mask], original.durations[small.mask],
col = plot.cols[small.mask], pch = plot.pch[small.mask], lwd = 2.5)
small.proposed.fit <- lm(duration.mean[small.mask] ~ true.durations.matching[small.mask] - 1)
small.proposed.slope <- small.proposed.fit$coefficients[1]
small.proposed.r2 <- summary(small.proposed.fit)$r.squared
segments(x0 = 0, y0 = 0, x1 = (20)/small.proposed.slope, y1 = 20, lwd = 4, col = "gray40", lty = 2) # best fit
small.naive.fit <- lm(original.durations[small.mask] ~ true.durations.matching[small.mask] - 1)
small.naive.slope <- small.naive.fit$coefficients[1]
r2 <- summary(small.naive.fit)$r.squared
segments(x0 = 0, y0 = 0, x1 = (20)/small.naive.slope, y1 = 20, lwd = 4, col = "gray40", lty = 3) # best fit
round(100 * sum(p.errors[small.mask] < 1 & p.errors[small.mask] > -0.5, na.rm= T) / sum(!is.na(p.errors[small.mask])), 1)
# round(100 * sum(p.errors[small.mask] < 0.5  & p.errors[small.mask] > -0.25, na.rm= T) / sum(!is.na(p.errors[small.mask])), 1)
round(100 * sum(p.errors[small.mask] < 2  & p.errors[small.mask] > -2/3, na.rm= T) / sum(!is.na(p.errors[small.mask])), 1)
legend("bottomleft",
legend = c("Proposed method (best fit line)", "Naive method (best fit line)"),
pch = tank.pch,
pt.bg = c("black", NA),
pt.lwd = c(2.5,2),
box.col = "white",
inset = c(0.1, 0.05))
axis.vals <- c(0,12)
plot(true.durations.matching[big.mask], duration.mean[big.mask],
col = "white",
pch = plot.pch[big.mask],
asp = 1,
xlim = axis.vals, ylim = axis.vals,
xlab = "True duration [hrs]",
ylab = "")
envelopePlot(x1 = seq(0, 20, by= 1), y1 = seq(0, 10, by = 0.5), y2 = seq(0,40, by = 2),
col = "gray90", lineCol = NA)
segments(x0 = 0, y0 = 0, x1 = 40, y1 = 40, lwd = 3, lty = 1) # 1:1
segments(x0 = true.durations.matching[big.mask],
y0 = duration.bound.lower[big.mask], y1 = duration.bound.upper[big.mask],
col = alpha(plot.cols[big.mask], 0.5))
points(true.durations.matching[big.mask], duration.mean[big.mask],
col = plot.cols[big.mask], bg = plot.cols[big.mask], pch = plot.pch[big.mask])
points(true.durations.matching[big.mask], original.durations[big.mask],
col = plot.cols[big.mask], pch = plot.pch[big.mask], lwd = 2.5)
big.proposed.fit <- lm(duration.mean[big.mask] ~ true.durations.matching[big.mask] - 1)
big.proposed.slope <- big.proposed.fit$coefficients[1]
big.proposed.r2 <- summary(big.proposed.fit)$r.squared
segments(x0 = 0, y0 = 0, x1 = (20)/big.proposed.slope, y1 = 20, lwd = 4, col = "gray40", lty = 2) # best fit
big.naive.fit <- lm(original.durations[big.mask] ~ true.durations.matching[big.mask] - 1)
big.naive.slope <- big.naive.fit$coefficients[1]
r2 <- summary(big.naive.fit)$r.squared
segments(x0 = 0, y0 = 0, x1 = (20)/big.naive.slope, y1 = 20, lwd = 4, col = "gray40", lty = 3) # best fit
round(100 * sum(p.errors[big.mask] < 1 & p.errors[big.mask] > -0.5, na.rm= T) / sum(!is.na(p.errors[big.mask])), 1)
# round(100 * sum(p.errors[big.mask] < 0.5  & p.errors[big.mask] > -0.25, na.rm= T) / sum(!is.na(p.errors[big.mask])), 1)
round(100 * sum(p.errors[big.mask] < 2  & p.errors[big.mask] > -2/3, na.rm= T) / sum(!is.na(p.errors[big.mask])), 1)
dev.off()
p.errors <- 100 * errors.mean / true.durations.matching
hist(p.errors, breaks = 20)
round(mean(p.errors, na.rm = T), 1)
round(quantile(p.errors, probs = c(0.05, 0.95), na.rm = T), 1)
round(100*sum(p.errors >= -0.5 & p.errors < 1, na.rm = T) / sum(!is.na(p.errors)), 1)
errors.mean
p.errors <- (duration.mean - true.durations.matching) / true.durations.matching
p.errrors
duration.mean
true.durations.matching
true.durations.matching
p.errors <- (duration.mean - true.durations.matching) / true.durations.matching
p.errors
round(100*sum(p.errors >= -0.5 & p.errors < 1, na.rm = T) / sum(!is.na(p.errors)), 1)
paste0(save.dir, t, ".png")
save.dir <- '../'
paste0(save.dir, t, ".png")
paste0(save.dir, 'METEC_results_', z, '_sensors.png')
source("~/Documents/code/CMS-durations/code/METEC_evaluation.R", echo=TRUE)
